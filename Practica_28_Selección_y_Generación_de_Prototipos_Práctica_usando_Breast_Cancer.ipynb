{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg2CWY8U9tMC9V5oXmWIIC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaustoFLES/Programacion-Analitica/blob/main/Practica_28_Selecci%C3%B3n_y_Generaci%C3%B3n_de_Prototipos_Pr%C3%A1ctica_usando_Breast_Cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==========================================================================\n",
        "#  Tarea: Reducci贸n de la Numerosidad con CNN, ENN y K-medias usando SVM\n",
        "#  Dataset: Breast Cancer (Scikit-Learn)\n",
        "#  Autor/a: Fausto Leyva\n",
        "#  Fecha: [11/15/2025]\n",
        "# ==========================================================================\n",
        "\n",
        "##  Descripci贸n:\n",
        "En este cuaderno aplicar谩s t茅cnicas de reducci贸n de la numerosidad (CNN, ENN, K-medias) al conjunto de datos Breast Cancer y analizar谩s su efecto en el rendimiento de un modelo SVM."
      ],
      "metadata": {
        "id": "l1UmIdmp-oTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ==========================================================================\n",
        "\n",
        "## 1. Cargar librer铆as necesarias\n",
        "Escribe aqu铆 la importaci贸n de librer铆as: numpy, pandas, matplotlib, seaborn, sklearn (datasets, model_selection, preprocessing, metrics, svm, kmeans), etc.\n",
        "\n",
        "En el caso de los c贸digos de ENN, CNN, estos  deber谩s tomarlos del cuaderno que contiene la teor铆a y ejemplos."
      ],
      "metadata": {
        "id": "o_vcG41mC0nF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "RYF0tn4WdneZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "\n",
        "## 2. Cargar y explorar el conjunto de datos Breast Cancer\n",
        "- Cargar el dataset con sklearn.datasets.load_breast_cancer\n",
        "- Explora las dimensiones, variables, y distribuci贸n de clases"
      ],
      "metadata": {
        "id": "03D7tleCEOcB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RtdC-KSc_dz",
        "outputId": "8ba32ea3-9c18-464e-eb34-80dc47901048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de datos de Breast Cancer cargado exitosamente.\n",
            "Caracter铆sticas: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "Clases objetivo: ['malignant' 'benign']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "breast_cancer = load_breast_cancer()\n",
        "print(\"Conjunto de datos de Breast Cancer cargado exitosamente.\")\n",
        "print(f\"Caracter铆sticas: {breast_cancer.feature_names}\")\n",
        "print(f\"Clases objetivo: {breast_cancer.target_names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "\n",
        "## 3. Preprocesamiento\n",
        " - Escalamiento de caracter铆sticas (StandardScaler)\n",
        " - Divisi贸n del conjunto en entrenamiento y prueba\n",
        " - usar hold-out de 70% y 30%\n",
        "\n"
      ],
      "metadata": {
        "id": "ZSwe1IaJElwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar caracter铆sticas (X) y objetivo (y)\n",
        "X = breast_cancer.data\n",
        "y = breast_cancer.target\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Inicializar y aplicar StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Caracter铆sticas escaladas y datos divididos en conjuntos de entrenamiento y prueba.\")\n",
        "print(f\"Dimensiones de X_train_scaled: {X_train_scaled.shape}\")\n",
        "print(f\"Dimensiones de X_test_scaled: {X_test_scaled.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM1xdzg9d0SS",
        "outputId": "99b0fb81-1fc2-4ca5-a955-dcb7ecb28d32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caracter铆sticas escaladas y datos divididos en conjuntos de entrenamiento y prueba.\n",
            "Dimensiones de X_train_scaled: (398, 30)\n",
            "Dimensiones de X_test_scaled: (171, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Los datos ya han sido divididos en conjuntos de entrenamiento y prueba en el paso anterior.\n",
        "# X_train, X_test, y_train, y_test ya est谩n definidos y escalados.\n",
        "print(\"Los datos ya han sido divididos en conjuntos de entrenamiento y prueba.\")\n",
        "print(f\"Dimensiones de X_train_scaled: {X_train_scaled.shape}\")\n",
        "print(f\"Dimensiones de X_test_scaled: {X_test_scaled.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFiNfB2Fd7ji",
        "outputId": "233fafa7-bb3f-4ab5-932e-7c3acbcb5902"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los datos ya han sido divididos en conjuntos de entrenamiento y prueba.\n",
            "Dimensiones de X_train_scaled: (398, 30)\n",
            "Dimensiones de X_test_scaled: (171, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirmaci贸n: La divisi贸n de hold-out ya se ha realizado con 70% para entrenamiento y 30% para prueba.\n",
        "# Esto fue configurado con `test_size=0.3` en la funci贸n `train_test_split`.\n",
        "print(\"La divisi贸n del conjunto de datos en entrenamiento (70%) y prueba (30%) ya ha sido aplicada.\")\n",
        "print(f\"Tama帽o del conjunto de entrenamiento (X_train_scaled): {X_train_scaled.shape[0]} muestras\")\n",
        "print(f\"Tama帽o del conjunto de prueba (X_test_scaled): {X_test_scaled.shape[0]} muestras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un5pd8A5eAJ5",
        "outputId": "a5e7e09b-1ccf-4c14-cf77-d8442160829d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La divisi贸n del conjunto de datos en entrenamiento (70%) y prueba (30%) ya ha sido aplicada.\n",
            "Tama帽o del conjunto de entrenamiento (X_train_scaled): 398 muestras\n",
            "Tama帽o del conjunto de prueba (X_test_scaled): 171 muestras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "\n",
        "## 4. Aplicar t茅cnica CNN (Condensed Nearest Neighbor)\n",
        "\n",
        "- Aplicar CNN sobre el conjunto de entrenamiento\n",
        "- Mostrar el tama帽o del conjunto reducido\n",
        "\n"
      ],
      "metadata": {
        "id": "6oNQfP5uEw0K"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02e71a7f",
        "outputId": "711ea710-27e6-46a5-d1b3-8102083d0153"
      },
      "source": [
        "from imblearn.under_sampling import CondensedNearestNeighbour\n",
        "\n",
        "# Instantiate CondensedNearestNeighbour\n",
        "cnn = CondensedNearestNeighbour(random_state=42)\n",
        "\n",
        "# Apply CNN to the scaled training set\n",
        "X_train_resampled, y_train_resampled = cnn.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Condensed Nearest Neighbor (CNN) aplicado exitosamente.\")\n",
        "print(f\"Tama帽o original del conjunto de entrenamiento: {X_train_scaled.shape[0]} muestras\")\n",
        "print(f\"Tama帽o del conjunto de entrenamiento reducido por CNN: {X_train_resampled.shape[0]} muestras\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Condensed Nearest Neighbor (CNN) aplicado exitosamente.\n",
            "Tama帽o original del conjunto de entrenamiento: 398 muestras\n",
            "Tama帽o del conjunto de entrenamiento reducido por CNN: 185 muestras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "3d8a4f80",
        "outputId": "00fdff42-a457-42bf-cd14-ce4dac217a2a"
      },
      "source": [
        "from imblearn.under_sampling import EditedNearestNeighbours\n",
        "\n",
        "# Instantiate EditedNearestNeighbours\n",
        "enn = EditedNearestNeighbours(random_state=42)\n",
        "\n",
        "# Apply ENN to the scaled training set\n",
        "X_train_enn, y_train_enn = enn.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Edited Nearest Neighbours (ENN) aplicado exitosamente.\")\n",
        "print(f\"Tama帽o original del conjunto de entrenamiento: {X_train_scaled.shape[0]} muestras\")\n",
        "print(f\"Tama帽o del conjunto de entrenamiento reducido por ENN: {X_train_enn.shape[0]} muestras\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "EditedNearestNeighbours.__init__() got an unexpected keyword argument 'random_state'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1788298144.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Instantiate EditedNearestNeighbours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0menn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEditedNearestNeighbours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Apply ENN to the scaled training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: EditedNearestNeighbours.__init__() got an unexpected keyword argument 'random_state'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " --------------------------------------------------------------------------\n",
        "\n",
        "## 5. Aplicar t茅cnica ENN (Edited Nearest Neighbor)\n",
        "\n",
        "- Aplicar ENN sobre el conjunto de entrenamiento\n",
        "- Mostrar el tama帽o del conjunto reducido\n",
        "\n"
      ],
      "metadata": {
        "id": "daewc7MNFGcG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1603036",
        "outputId": "ab985dd4-c8e9-4d0b-c4e0-9720008a4bb6"
      },
      "source": [
        "from imblearn.under_sampling import EditedNearestNeighbours\n",
        "\n",
        "# Instantiate EditedNearestNeighbours without random_state\n",
        "enn = EditedNearestNeighbours()\n",
        "\n",
        "# Apply ENN to the scaled training set\n",
        "X_train_enn, y_train_enn = enn.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Edited Nearest Neighbours (ENN) aplicado exitosamente.\")\n",
        "print(f\"Tama帽o original del conjunto de entrenamiento: {X_train_scaled.shape[0]} muestras\")\n",
        "print(f\"Tama帽o del conjunto de entrenamiento reducido por ENN: {X_train_enn.shape[0]} muestras\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edited Nearest Neighbours (ENN) aplicado exitosamente.\n",
            "Tama帽o original del conjunto de entrenamiento: 398 muestras\n",
            "Tama帽o del conjunto de entrenamiento reducido por ENN: 376 muestras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "\n",
        "## 6. Aplicar reducci贸n mediante K-medias\n",
        "- Realizar agrupamiento por clase y representar cada grupo con su centroide. Elige la mitad de los elementos de cada clase como el valor del n煤mero de centroides\n",
        "- Generar un nuevo conjunto reducido con los centroides como prototipos\n",
        "\n"
      ],
      "metadata": {
        "id": "PGF6IzcTFOK7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63f76d76",
        "outputId": "db6fbc47-748d-445f-ec6b-a4104c2a59bb"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "\n",
        "# Instantiate KMeans with an appropriate number of clusters and random_state\n",
        "n_clusters = 10  # Example: choosing 10 clusters for reduction\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')\n",
        "\n",
        "# Fit KMeans to the scaled training set\n",
        "kmeans.fit(X_train_scaled)\n",
        "\n",
        "# Get the cluster centroids as the new reduced features\n",
        "X_train_kmeans = kmeans.cluster_centers_\n",
        "\n",
        "# Predict the cluster labels for the original training data\n",
        "cluster_labels = kmeans.predict(X_train_scaled)\n",
        "\n",
        "# Determine the majority class for each centroid\n",
        "y_train_kmeans = np.array([0] * n_clusters) # Initialize array for new labels\n",
        "for i in range(n_clusters):\n",
        "    # Get the indices of samples belonging to the current cluster\n",
        "    cluster_indices = np.where(cluster_labels == i)[0]\n",
        "    if len(cluster_indices) > 0:\n",
        "        # Get the true labels of these samples\n",
        "        labels_in_cluster = y_train[cluster_indices]\n",
        "        # Find the majority class\n",
        "        majority_class = Counter(labels_in_cluster).most_common(1)[0][0]\n",
        "        y_train_kmeans[i] = majority_class\n",
        "    else:\n",
        "        # If a cluster is empty, assign a default class (e.g., 0) or handle as appropriate\n",
        "        y_train_kmeans[i] = 0 # Assigning 0 as a placeholder for empty clusters\n",
        "\n",
        "print(\"K-means aplicado exitosamente.\")\n",
        "print(f\"Tama帽o original del conjunto de entrenamiento: {X_train_scaled.shape[0]} muestras\")\n",
        "print(f\"Tama帽o del conjunto de entrenamiento reducido por K-means: {X_train_kmeans.shape[0]} muestras\")\n",
        "print(f\"El nuevo conjunto de etiquetas y_train_kmeans tiene tama帽o: {y_train_kmeans.shape[0]}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-means aplicado exitosamente.\n",
            "Tama帽o original del conjunto de entrenamiento: 398 muestras\n",
            "Tama帽o del conjunto de entrenamiento reducido por K-means: 10 muestras\n",
            "El nuevo conjunto de etiquetas y_train_kmeans tiene tama帽o: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " --------------------------------------------------------------------------\n",
        "\n",
        "##7. Entrenar SVM sobre cada conjunto reducido\n",
        "- Entrenar un modelo SVM (SVC) sobre:\n",
        " * los datos originales\n",
        " * datos reducidos con CNN\n",
        " * datos reducidos con ENN\n",
        " * datos reducidos con K-medias\n",
        "- Evaluar cada modelo con accuracy, F1-score\n",
        "\n"
      ],
      "metadata": {
        "id": "euUiDoqyFclR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03bd0610",
        "outputId": "df2c6726-734f-4d5e-afda-82c15acced76"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Instantiate the SVC model\n",
        "svm_baseline = SVC(random_state=42)\n",
        "\n",
        "# Train the SVM model on the original scaled training set\n",
        "svm_baseline.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"SVM classifier entrenado en el conjunto de entrenamiento escalado original.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classifier entrenado en el conjunto de entrenamiento escalado original.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8a25338",
        "outputId": "b9f4c996-8d7c-4801-b818-a34979899c19"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Instantiate the SVC model\n",
        "svm_cnn = SVC(random_state=42)\n",
        "\n",
        "# Train the SVM model on the CNN-reduced training set\n",
        "svm_cnn.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"SVM classifier entrenado en el conjunto de entrenamiento reducido por CNN.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classifier entrenado en el conjunto de entrenamiento reducido por CNN.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ea4e6b",
        "outputId": "97ab6933-1891-46b1-8101-3f77e5ceba59"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Instantiate the SVC model\n",
        "svm_enn = SVC(random_state=42)\n",
        "\n",
        "# Train the SVM model on the ENN-reduced training set\n",
        "svm_enn.fit(X_train_enn, y_train_enn)\n",
        "\n",
        "print(\"SVM classifier entrenado en el conjunto de entrenamiento reducido por ENN.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classifier entrenado en el conjunto de entrenamiento reducido por ENN.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a70599e9",
        "outputId": "5d09fd5f-eedb-404d-bcdb-6596e6f432ca"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Instantiate the SVC model\n",
        "svm_kmeans = SVC(random_state=42)\n",
        "\n",
        "# Train the SVM model on the K-means-reduced training set\n",
        "svm_kmeans.fit(X_train_kmeans, y_train_kmeans)\n",
        "\n",
        "print(\"SVM classifier entrenado en el conjunto de entrenamiento reducido por K-means.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classifier entrenado en el conjunto de entrenamiento reducido por K-means.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c32201b9",
        "outputId": "5fea3c5f-b799-4986-d388-af860e0b94c7"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba con el modelo baseline\n",
        "y_pred_baseline = svm_baseline.predict(X_test_scaled)\n",
        "\n",
        "# Calcular y mostrar la precisi贸n\n",
        "accuracy_baseline = accuracy_score(y_test, y_pred_baseline)\n",
        "print(f\"Precisi贸n del SVM (l铆nea base): {accuracy_baseline:.4f}\")\n",
        "\n",
        "# Mostrar el informe de clasificaci贸n\n",
        "print(\"\\nInforme de Clasificaci贸n (l铆nea base):\\n\")\n",
        "print(classification_report(y_test, y_pred_baseline))\n",
        "\n",
        "# Mostrar la matriz de confusi贸n\n",
        "print(\"\\nMatriz de Confusi贸n (l铆nea base):\\n\")\n",
        "print(confusion_matrix(y_test, y_pred_baseline))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisi贸n del SVM (l铆nea base): 0.9766\n",
            "\n",
            "Informe de Clasificaci贸n (l铆nea base):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        63\n",
            "           1       0.98      0.98      0.98       108\n",
            "\n",
            "    accuracy                           0.98       171\n",
            "   macro avg       0.97      0.97      0.97       171\n",
            "weighted avg       0.98      0.98      0.98       171\n",
            "\n",
            "\n",
            "Matriz de Confusi贸n (l铆nea base):\n",
            "\n",
            "[[ 61   2]\n",
            " [  2 106]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aee9fcad",
        "outputId": "fe1c10bf-e247-4645-ea67-6c7eed6fa137"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba con el modelo SVM entrenado con CNN\n",
        "y_pred_cnn = svm_cnn.predict(X_test_scaled)\n",
        "\n",
        "# Calcular y mostrar la precisi贸n\n",
        "accuracy_cnn = accuracy_score(y_test, y_pred_cnn)\n",
        "print(f\"Precisi贸n del SVM (CNN-reducido): {accuracy_cnn:.4f}\")\n",
        "\n",
        "# Mostrar el informe de clasificaci贸n\n",
        "print(\"\\nInforme de Clasificaci贸n (CNN-reducido):\\n\")\n",
        "print(classification_report(y_test, y_pred_cnn))\n",
        "\n",
        "# Mostrar la matriz de confusi贸n\n",
        "print(\"\\nMatriz de Confusi贸n (CNN-reducido):\\n\")\n",
        "print(confusion_matrix(y_test, y_pred_cnn))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisi贸n del SVM (CNN-reducido): 0.9298\n",
            "\n",
            "Informe de Clasificaci贸n (CNN-reducido):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.98      0.91        63\n",
            "           1       0.99      0.90      0.94       108\n",
            "\n",
            "    accuracy                           0.93       171\n",
            "   macro avg       0.92      0.94      0.93       171\n",
            "weighted avg       0.94      0.93      0.93       171\n",
            "\n",
            "\n",
            "Matriz de Confusi贸n (CNN-reducido):\n",
            "\n",
            "[[62  1]\n",
            " [11 97]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6d2a272",
        "outputId": "1bac8254-ca69-48f2-eb0d-89b64b5ae495"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba con el modelo SVM entrenado con ENN\n",
        "y_pred_enn = svm_enn.predict(X_test_scaled)\n",
        "\n",
        "# Calcular y mostrar la precisi贸n\n",
        "accuracy_enn = accuracy_score(y_test, y_pred_enn)\n",
        "print(f\"Precisi贸n del SVM (ENN-reducido): {accuracy_enn:.4f}\")\n",
        "\n",
        "# Mostrar el informe de clasificaci贸n\n",
        "print(\"\\nInforme de Clasificaci贸n (ENN-reducido):\\n\")\n",
        "print(classification_report(y_test, y_pred_enn))\n",
        "\n",
        "# Mostrar la matriz de confusi贸n\n",
        "print(\"\\nMatriz de Confusi贸n (ENN-reducido):\\n\")\n",
        "print(confusion_matrix(y_test, y_pred_enn))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisi贸n del SVM (ENN-reducido): 0.9708\n",
            "\n",
            "Informe de Clasificaci贸n (ENN-reducido):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96        63\n",
            "           1       0.98      0.97      0.98       108\n",
            "\n",
            "    accuracy                           0.97       171\n",
            "   macro avg       0.97      0.97      0.97       171\n",
            "weighted avg       0.97      0.97      0.97       171\n",
            "\n",
            "\n",
            "Matriz de Confusi贸n (ENN-reducido):\n",
            "\n",
            "[[ 61   2]\n",
            " [  3 105]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38b2eea8",
        "outputId": "fb3da2d2-108b-4eb7-cedf-185d6abab2cf"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba con el modelo SVM entrenado con K-means\n",
        "y_pred_kmeans = svm_kmeans.predict(X_test_scaled)\n",
        "\n",
        "# Calcular y mostrar la precisi贸n\n",
        "accuracy_kmeans = accuracy_score(y_test, y_pred_kmeans)\n",
        "print(f\"Precisi贸n del SVM (K-means-reducido): {accuracy_kmeans:.4f}\")\n",
        "\n",
        "# Mostrar el informe de clasificaci贸n\n",
        "print(\"\\nInforme de Clasificaci贸n (K-means-reducido):\\n\")\n",
        "print(classification_report(y_test, y_pred_kmeans))\n",
        "\n",
        "# Mostrar la matriz de confusi贸n\n",
        "print(\"\\nMatriz de Confusi贸n (K-means-reducido):\\n\")\n",
        "print(confusion_matrix(y_test, y_pred_kmeans))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisi贸n del SVM (K-means-reducido): 0.9123\n",
            "\n",
            "Informe de Clasificaci贸n (K-means-reducido):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87        63\n",
            "           1       0.88      0.99      0.93       108\n",
            "\n",
            "    accuracy                           0.91       171\n",
            "   macro avg       0.93      0.88      0.90       171\n",
            "weighted avg       0.92      0.91      0.91       171\n",
            "\n",
            "\n",
            "Matriz de Confusi贸n (K-means-reducido):\n",
            "\n",
            "[[ 49  14]\n",
            " [  1 107]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0b84f7d",
        "outputId": "b3e00c3b-f8be-42ff-f64c-f5cb1056e1ed"
      },
      "source": [
        "accuracy_scores = {\n",
        "    \"SVM Baseline\": accuracy_baseline,\n",
        "    \"SVM with CNN\": accuracy_cnn,\n",
        "    \"SVM with ENN\": accuracy_enn,\n",
        "    \"SVM with K-means\": accuracy_kmeans\n",
        "}\n",
        "\n",
        "print(\"Accuracies of SVM models with different reduction techniques:\")\n",
        "for model, accuracy in accuracy_scores.items():\n",
        "    print(f\"- {model}: {accuracy:.4f}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracies of SVM models with different reduction techniques:\n",
            "- SVM Baseline: 0.9766\n",
            "- SVM with CNN: 0.9298\n",
            "- SVM with ENN: 0.9708\n",
            "- SVM with K-means: 0.9123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "\n",
        "##  8. Comparar los resultados y reflexi贸n final\n",
        "- Comparar las m茅tricas de rendimiento obtenidas con cada t茅cnica\n",
        "- Escribe tus conclusiones sobre el impacto de la reducci贸n de la numerosidad\n",
        "- 驴Cu谩l t茅cnica funcion贸 mejor? 驴Qu茅 ventajas y desventajas observaste?\n",
        "\n"
      ],
      "metadata": {
        "id": "wjwq_4BWF2_b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10722e0d"
      },
      "source": [
        "## An谩lisis de Resultados\n",
        "\n",
        "### Comparaci贸n de Precisiciones:\n",
        "\n",
        "*   **SVM L铆nea Base:** 0.9766\n",
        "*   **SVM con CNN:** 0.9298\n",
        "*   **SVM con ENN:** 0.9708\n",
        "*   **SVM con K-means:** 0.9123\n",
        "\n",
        "### Observaciones Clave y An谩lisis:\n",
        "\n",
        "1.  **L铆nea Base (Original):** El modelo SVM entrenado con el conjunto de datos escalado original (`X_train_scaled`, `y_train`) obtuvo una precisi贸n del **0.9766**. Este es el punto de referencia para evaluar el impacto de las t茅cnicas de reducci贸n.\n",
        "\n",
        "2.  **Impacto de ENN:** La t茅cnica de **Edited Nearest Neighbours (ENN)** result贸 en una precisi贸n del **0.9708**. Esta es la m谩s cercana a la l铆nea base, lo que sugiere que ENN fue la t茅cnica de reducci贸n que tuvo el **menor impacto negativo** (o casi nulo) en el rendimiento del modelo SVM. ENN elimina instancias ruidosas o superpuestas, lo que puede mejorar la calidad del conjunto de datos sin perder informaci贸n crucial para la clasificaci贸n.\n",
        "\n",
        "3.  **Impacto de CNN:** La t茅cnica de **Condensed Nearest Neighbour (CNN)** redujo la precisi贸n a **0.9298**. Aunque sigue siendo un rendimiento aceptable, muestra una ca铆da m谩s notable en comparaci贸n con la l铆nea base y ENN. CNN se enfoca en mantener solo los puntos esenciales para definir los l铆mites de decisi贸n, lo que puede llevar a una mayor reducci贸n de datos pero con una posible p茅rdida de generalizaci贸n.\n",
        "\n",
        "4.  **Impacto de K-means:** La t茅cnica de **K-medias** para reducci贸n de numerosidad (utilizando los centroides como nuevas instancias y asignando la clase mayoritaria) result贸 en la precisi贸n m谩s baja de **0.9123**. K-means realiza una reducci贸n dr谩stica, especialmente si el n煤mero de clusters (`n_clusters = 10` en este caso) es significativamente menor que el n煤mero original de muestras. Esta reducci贸n agresiva puede simplificar demasiado la distribuci贸n de los datos, llevando a una p茅rdida de informaci贸n que afecta negativamente la capacidad del SVM para clasificar correctamente.\n",
        "\n",
        "### Trade-off entre Reducci贸n y Rendimiento:\n",
        "\n",
        "*   **ENN** parece ofrecer un excelente equilibrio, logrando una reducci贸n de datos (de 398 a 376 muestras) con una m铆nima p茅rdida de precisi贸n. Esto indica que las instancias eliminadas por ENN eran probablemente ruidosas o redundantes.\n",
        "*   **CNN** logr贸 una reducci贸n m谩s sustancial (de 398 a 185 muestras) pero con un compromiso en la precisi贸n. Esto puede ser aceptable en escenarios donde la velocidad de entrenamiento es cr铆tica y se puede tolerar una ligera disminuci贸n en el rendimiento.\n",
        "*   **K-means** con un n煤mero bajo de clusters (10) result贸 en la mayor reducci贸n de datos (de 398 a 10 muestras), pero tambi茅n en la mayor penalizaci贸n en la precisi贸n. Esto resalta que una reducci贸n muy agresiva, aunque acelere el entrenamiento, puede no ser adecuada para mantener la calidad predictiva del modelo, especialmente si la complejidad de los datos es alta."
      ]
    }
  ]
}